import os
import chromadb
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def load_corpus(file_path: str) -> str:
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()


def split_into_chunks(text: str, chunk_size: int = 500, chunk_overlap: int = 50):
    chunks = []
    start = 0
    text_length = len(text)

    while start < text_length:
        end = min(start + chunk_size, text_length)
        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)
        start += chunk_size - chunk_overlap

    return chunks


def build_vector_store(chunks):
    client_chroma = chromadb.Client()
    collection = client_chroma.create_collection(name="noi_quy_cong_ty")

    ids = [f"chunk_{i}" for i in range(len(chunks))]
    metadatas = [{"source": "noi_quy_cong_ty", "chunk_id": i} for i in range(len(chunks))]

    collection.add(
        ids=ids,
        documents=chunks,
        metadatas=metadatas,
    )

    return collection


def retrieve_relevant_chunks(collection, question: str, top_k: int = 3):
    results = collection.query(
        query_texts=[question],
        n_results=top_k,
    )
    docs = results["documents"][0]
    return docs


def answer_question_with_context(question: str, context_chunks):
    context_text = "\n\n---\n\n".join(context_chunks)

    system_prompt = (
        "Báº¡n lÃ  chatbot ná»™i bá»™ cá»§a cÃ´ng ty. "
        "Báº¡n chá»‰ Ä‘Æ°á»£c tráº£ lá»i dá»±a trÃªn ná»™i dung ná»™i quy cÃ´ng ty Ä‘Æ°á»£c cung cáº¥p dÆ°á»›i Ä‘Ã¢y. "
        "Náº¿u khÃ´ng tÃ¬m tháº¥y cÃ¢u tráº£ lá»i, hÃ£y nÃ³i 'TÃ´i khÃ´ng cháº¯c theo ná»™i quy hiá»‡n táº¡i.'"
    )

    user_content = (
        f"Ná»™i quy cÃ´ng ty:\n{context_text}\n\n"
        f"CÃ¢u há»i cá»§a nhÃ¢n viÃªn: {question}\n\n"
        "Tráº£ lá»i rÃµ rÃ ng, ngáº¯n gá»n báº±ng tiáº¿ng Viá»‡t."
    )

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content},
        ],
    )

    return resp.choices[0].message.content


if __name__ == "__main__":
    # 1. Load & index
    corpus = load_corpus("noi_quy_cong_ty.txt")
    chunks = split_into_chunks(corpus, chunk_size=500, chunk_overlap=50)
    collection = build_vector_store(chunks)

    print("=== Chatbot Ná»™i bá»™ â€“ Ná»™i quy CÃ´ng ty (RAG) ===")
    print("GÃµ cÃ¢u há»i vá» ná»™i quy cÃ´ng ty. Enter Ä‘á»ƒ thoÃ¡t.")

    # 2. Loop há»iâ€“Ä‘Ã¡p
    while True:
        question = input("\nðŸ‘¤ Báº¡n: ").strip()
        if not question:
            break

        context_chunks = retrieve_relevant_chunks(collection, question, top_k=3)
        answer = answer_question_with_context(question, context_chunks)

        print("\nðŸ¤– Bot:", answer)
